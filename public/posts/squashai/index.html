<!doctype html><html lang=en-us dir=ltr><head><meta charset=utf-8><meta name=viewport content="width=device-width"><link rel=icon type=image/ico href=https://mmkaram.github.io//favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://mmkaram.github.io//favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://mmkaram.github.io//favicon-32x32.png><link rel=icon type=image/png sizes=192x192 href=https://mmkaram.github.io//android-chrome-192x192.png><link rel=apple-touch-icon sizes=180x180 href=https://mmkaram.github.io//apple-touch-icon.png><meta name=description content><title>SquashAI | mmkaram</title><link rel=canonical href=https://mmkaram.github.io/posts/squashai/><meta property="og:url" content="https://mmkaram.github.io/posts/squashai/"><meta property="og:site_name" content="mmkaram"><meta property="og:title" content="SquashAI"><meta property="og:description" content="An autonomous Squash coach written in python, using OpenCV, TF, and Keras"><meta property="og:locale" content="en_us"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2024-01-03T00:00:00+00:00"><meta property="article:modified_time" content="2024-01-03T00:00:00+00:00"><link rel=stylesheet href=/assets/combined.min.186794b3399a702d3092949042cdc215dea303c17e71e7c0254768448de11db8.css media=all></head><body class=auto><div class=content><header><div class=header><h1 class=header-title><a href=https://mmkaram.github.io/>mmkaram</a></h1><div class=flex><p class=small><a href=/posts>/posts</a></p></div></div></header><main class=main><div class=breadcrumbs><a href=/>mmkaram</a>
<span class=breadcrumbs-separator>> </span><a href=/posts/>Posts</a>
<span class=breadcrumbs-separator>> </span><a class=breadcrumbs-current href=/posts/squashai/>SquashAI</a></div><div><div class=single-intro-container><h1 class=single-title>SquashAI</h1><p class=single-summary>An autonomous Squash coach written in python, using OpenCV, TF, and Keras</p><p class=single-readtime><time datetime=2024-01-03T00:00:00+00:00>January 3, 2024</time></p></div><div class=single-content><p>This is a rudimentary explanation of the of the Squash AI program, if you want more details, contact me via <a href=https://www.linkedin.com/in/mahdy-karam>LinkedIn</a>.</p><h4 class=heading id=introduction>Introduction
<a href=#introduction>#</a></h4><p>What is SquashAI? Why did I make it? And why is it important?</p><p>SquashAI is a mobile application intended to help squash players improve their game. It does this by providing a way to track the player&rsquo;s performance and provide feedback on how to improve. It also stores that information to track progress over time.</p><p>I made it because I wanted to improve my own game, and I thought I might as well put my programming skills to use. I also wanted to learn more about machine learning and computer vision, and this was a great way to do that.</p><p>As I progressed in the project, I realized that it could be used to help other players improve <em>their</em> game, especially people who don&rsquo;t don&rsquo;t come from economic backgrounds that can support paying for coaching fees. This should be way cheaper to run and democratize coaching for the masses. In addition, coaches aren&rsquo;t statisticians. They can&rsquo;t tell you how your game has changed over time with the accuracy that a computer can. Also, if all the other sports have stats like RBI (baseball), passing yards (american football), and PPG (basketball) why can&rsquo;t we? We&rsquo;re in the Olympics now, we better act like it.</p><h4 class=heading id=how-it-works>How it works
<a href=#how-it-works>#</a></h4><p>There is one point of data collection: the video. Recorded from a single smartphone, a video can either be streamed live into the program, or it can be uploaded from the device&rsquo;s storage.
Once there is a feed, the real work can begin. Three key data points are collected every frame:</p><ul><li>The position of the ball</li><li>The positions of both players</li><li>The bounds of the court</li></ul><h4 class=heading id=1-ball-tracking>1. Ball Tracking
<a href=#1-ball-tracking>#</a></h4><p>We can leverage basic computer vision techniques (KNN background detection, dilation, and more) with OpenCV to get the position of the ball ~90% of the time. This is based off an attempt by <a href=https://www.dmorris.co.uk>Duncan Morris</a>, but I&rsquo;ve made some changes to make it more robust<sup id=fnref:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup>. Effectively, the pipeline looks like this:
Video -> Preprocessing -> Background Subtraction -> Dilation -> Filtering -> Contour Detection -> Ball Position</p><h6 class=heading id=preprocessing>Preprocessing:
<a href=#preprocessing>#</a></h6><ul><li>resize the frame to <code>970 x 540</code> pixels</li><li>that&rsquo;s really it, we want to keep all the information we can</li></ul><h6 class=heading id=background-subtraction>Background Subtraction:
<a href=#background-subtraction>#</a></h6><ul><li>Using OpenCV&rsquo;s <code>createBackgroundSubtractorKNN()</code> function, we can get a mask of the background. It needs a frame count to use as history to compare the change in each pixel so it acn tell what has changed. A higher history isn&rsquo;t always better, because camera shake can change more pixels than intended, so ideally it&rsquo;s actually dynamic. There&rsquo;s another way we can optimize this too. We know the top possible speed of the ball, so we can limit the area it does the KNN calculations on<sup id=fnref:2><a href=#fn:2 class=footnote-ref role=doc-noteref>2</a></sup>.</li></ul><h6 class=heading id=dilation>Dilation:
<a href=#dilation>#</a></h6><blockquote><p><em>After a conversation with <a href=https://www.linkedin.com/in/drjoeweber/>Dr. Joe Webber</a>, I now know the way I&rsquo;m doing it isn&rsquo;t the best, so I&rsquo;ll update this when I implement his feedback</em>
The <a href=https://docs.opencv.org/3.4/db/d88/classcv_1_1BackgroundSubtractorKNN.html>KNN-Background Subtraction</a> leaves a lot of noise, so we can use dilation to get rid of it</p></blockquote><h6 class=heading id=filtering>Filtering:
<a href=#filtering>#</a></h6><blockquote><p><em>working on it, see that Dr. Webber comment above</em></p></blockquote><h6 class=heading id=contour-detection>Contour Detection:
<a href=#contour-detection>#</a></h6><p>Currently, I&rsquo;m using shilouette detection to identify what part of our dialated foreground is the ball. Turns out, we can actually use <a href=https://en.wikipedia.org/wiki/Connected-component_labeling>connected-components</a> instead. This requires less math, and is more accurate.
Finally, when rendered it looks like this (bottom left: KNN, top right: dialation, top left: contour detection overlayed on original frame):</p><p><figure><div><img loading=lazy alt="Ball Tracking" src=/images/ball_tracking.png></div></figure></p><h4 class=heading id=2-player-tracking>2. Player Tracking
<a href=#2-player-tracking>#</a></h4><p>Using the Apache 2.0 licensed <a href=https://github.com/geaxgx/openvino_movenet_multipose>MoveNet</a>, developed by Google, we can get the following data:</p><blockquote><p>&ldquo;A float32 tensor of shape [1, 1, 17, 3]. The first two channels of the last dimension represents the yx coordinates (normalized to image frame, i.e. range in [0.0, 1.0]) of the 17 keypoints (in the order of: [nose, left eye, right eye, left ear, right ear, left shoulder, right shoulder, left elbow, right elbow, left wrist, right wrist, left hip, right hip, left knee, right knee, left ankle, right ankle]).&rdquo; <sup id=fnref:3><a href=#fn:3 class=footnote-ref role=doc-noteref>3</a></sup>
Rendered:</p></blockquote><p><figure><div><img loading=lazy alt="Player Tracking" src=/images/player_tracking.png></div></figure></p><h4 class=heading id=3-court-analysis>3. Court analysis
<a href=#3-court-analysis>#</a></h4><p>Using openCV&rsquo;s powerful toolset, we can use functions like <code>getPerspectiveTransform()</code> to unwarp the court as we know the out and service lines are all straight (hopefully, if they aren&rsquo;t you&rsquo;re playing on a wack court).</p><div class=footnotes role=doc-endnotes><hr><ol><li id=fn:1><p>From Duncan Morris&rsquo;s <a href=https://www.dmorris.co.uk/squash/ball_detect.html>blog post</a>&#160;<a href=#fnref:1 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:2><p>The top speed of the ball ~267 kph (166 mph) according to <a href=https://www.guinnessworldrecords.com/world-records/63439-fastest-speed-of-a-squash-ball>Guinness World Records</a>&#160;<a href=#fnref:2 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:3><p>From <a href=https://storage.googleapis.com/movenet/MoveNet.SinglePose%20Model%20Card.pdf>Google&rsquo;s Writeup</a>&#160;<a href=#fnref:3 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li></ol></div></div><div class=single-pagination><hr><div class=flex><div class=single-pagination-prev></div><div class=single-pagination-next><div class=single-pagination-container-next><div class=single-pagination-text><a href=/posts/the-0k-engine/>The 0k engine</a></div><div class=single-pagination-text>â†’</div></div></div></div><hr></div><div class=back-to-top><a href=#top>back to top</a></div></div></main></div><footer><p>Powered by
<a href=https://gohugo.io/>Hugo</a>
and
<a href=https://github.com/tomfran/typo>tomfran/typo</a></p></footer></body><script>function isAuto(){return document.body.classList.contains("auto")}function setTheme(){if(!isAuto())return;document.body.classList.remove("auto");let e="light";window.matchMedia&&window.matchMedia("(prefers-color-scheme: dark)").matches&&(e="dark"),document.body.classList.add(e)}function invertBody(){document.body.classList.toggle("dark"),document.body.classList.toggle("light")}isAuto()&&window.matchMedia("(prefers-color-scheme: dark)").addListener(invertBody),setTheme()</script></html>